{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'categories': [{'categories': {'id': 1, 'name': 'Delivery'}}, {'categories': {'id': 2, 'name': 'Dine-out'}}, {'categories': {'id': 3, 'name': 'Nightlife'}}, {'categories': {'id': 4, 'name': 'Catching-up'}}, {'categories': {'id': 5, 'name': 'Takeaway'}}, {'categories': {'id': 6, 'name': 'Cafes'}}, {'categories': {'id': 7, 'name': 'Daily Menus'}}, {'categories': {'id': 8, 'name': 'Breakfast'}}, {'categories': {'id': 9, 'name': 'Lunch'}}, {'categories': {'id': 10, 'name': 'Dinner'}}, {'categories': {'id': 11, 'name': 'Pubs & Bars'}}, {'categories': {'id': 13, 'name': 'Pocket Friendly Delivery'}}, {'categories': {'id': 14, 'name': 'Clubs & Lounges'}}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "Key = '06e95084cb5d3426c57b51987827eb7d'\n",
    "url = \"https://developers.zomato.com/api/v2.1/categories\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    r = requests.get(url, headers={'user-key': Key})\n",
    "    if r.ok:\n",
    "        data = r.json()\n",
    "        print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params= {\n",
    "    'user-key': Key,\n",
    "    \"category\": 3,\n",
    "    \"city\": 280,\n",
    "    \"entity_type\": \"city\",\n",
    "}\n",
    "\n",
    "url = \"https://developers.zomato.com/api/v2.1/\"\n",
    "\n",
    "headers= {\n",
    "    \"user-key\":Key\n",
    "}\n",
    "results = requests.get(url,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5990537c6b86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mjson\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    894\u001b[0m                     \u001b[1;31m# used.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 896\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "results.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to BeautifulSoup and define the parser as HTML\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all apts that fit the specified criteria and # of apts\n",
    "apts = soup.find_all('p', attrs={'class':'result-info'})\n",
    "print(len(apts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Parse through Craigslist results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results are returned as an iterable list\n",
    "results = soup.find_all('li', class_=\"result-row\")\n",
    "list_results = []\n",
    "\n",
    "\n",
    "# Loop through returned results\n",
    "for result in results:\n",
    "    # Error handling\n",
    "    try:\n",
    "        # Identify and return title of listing\n",
    "        title = result.find('a', class_=\"result-title\").text\n",
    "        # Identify and return price of listing\n",
    "        price = result.a.span.text.strip('$')\n",
    "        # Identify number of rooms\n",
    "        n_rooms = result.find('span', class_ = 'housing').text.split()\n",
    "        # Identify and return link to listing\n",
    "        link = result.a['href']\n",
    "        # Identify posting date\n",
    "        post_time = result.find('time')['datetime']\n",
    "        post_time = pd.to_datetime(post_time)\n",
    "        # Identify neighborhood\n",
    "        neighborhood = result.find('span', class_= 'result-hood').text\n",
    "        \n",
    "        list_results.append({'#bedrooms': n_rooms, '$price': price,\n",
    "                        'Post_Title': title, 'URL': link, 'Post_Time': post_time, 'Neighborhood': neighborhood})\n",
    "        \n",
    "        # Print results only if title, price, and link are available\n",
    "        if (title and price and link):\n",
    "            print('-------------')\n",
    "            print(title)\n",
    "            print(price)\n",
    "            print(n_rooms)\n",
    "            print(link)\n",
    "            print(post_time)\n",
    "            print(neighborhood)\n",
    "    except AttributeError as e:\n",
    "        print(e)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame from results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "apt_df = pd.DataFrame(list_results)\n",
    "\n",
    "# Clean data and remove text for room/ \n",
    "bedrooms = apt_df['#bedrooms']\n",
    "rooms = []\n",
    "\n",
    "for room in bedrooms:\n",
    "    rooms.append(room[0].strip('br'))\n",
    "\n",
    "apt_df['#rooms'] = rooms\n",
    "apt_df['Post_Time'] = apt_df['Post_Time'].dt.date\n",
    "\n",
    "apt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clean data and remove text from #bedrooms and create new column for sqft \n",
    "\n",
    "# Split before and after the dash & remove the 'ft2' text\n",
    "apt_df['#bedrooms'] = apt_df['#bedrooms'].astype(str)\n",
    "apt_df['#bedrooms'] = apt_df['#bedrooms'].str.split(',').str[2]\n",
    "apt_df['#bedrooms'].fillna(\"\", inplace=True)\n",
    "apt_df['#bedrooms'] = apt_df['#bedrooms'].str.split('ft2') \n",
    "\n",
    "###############################################################\n",
    "\n",
    "# Loop through the new bedroom values and remove remaining text that will prevent converting to int\n",
    "bedrooms = apt_df['#bedrooms']\n",
    "rooms = []\n",
    "\n",
    "for room in bedrooms:\n",
    "    rooms.append(room[0].strip(','))\n",
    "\n",
    "apt_df['sqft'] = rooms\n",
    "apt_df['sqft'] = apt_df['sqft'].str.replace(r\"'\", '')\n",
    "apt_df['sqft'] = apt_df['sqft'].astype(str)\n",
    "apt_df['sqft'] = apt_df['sqft'].str.strip()\n",
    "\n",
    "##############################################################\n",
    "\n",
    "# Convert values to int and if NAN make = 0\n",
    "sqfts = apt_df['sqft']\n",
    "number = []\n",
    "\n",
    "for sqft in sqfts:\n",
    "    number.append(sqft)\n",
    "\n",
    "newsqft = pd.to_numeric(number, errors='ignore')\n",
    "apt_df['sqft'] = newsqft\n",
    "apt_df['sqft'].fillna(\"0\", inplace=True)\n",
    "apt_df['sqft'] = apt_df['sqft'].astype(int)\n",
    "\n",
    "##############################################################\n",
    "\n",
    "# Convert price and # rooms to int in order to graph data\n",
    "apt_df['$price'] = apt_df['$price'].astype(int)\n",
    "apt_df['#rooms'] = apt_df['#rooms'].astype(int)\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "# Clean up the Neighborhood name\n",
    "apt_df['Hood'] = apt_df['Neighborhood'].str.extract(r\"\\((.*?)\\)\", expand=False)\n",
    "apt_df['Hood'] = apt_df['Hood'].astype(str)\n",
    "apt_df['Hood'] = apt_df['Hood'].str.strip()\n",
    "\n",
    "neighborhoods = apt_df[\"Hood\"].unique()\n",
    "new_hoods = ['North Beach', 'Lower Nob Hill', 'Nob Hill', 'Russian Hill', 'Lower Pac Hts', 'Pac Heights']\n",
    "my_dict = dict(zip(neighborhoods, new_hoods))\n",
    "\n",
    "apt_df['Hood'].replace(my_dict, inplace=True)\n",
    "\n",
    "\n",
    "apt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# New DataFrame to build graphs in\n",
    "apts_data = apt_df[['#rooms', 'sqft', '$price', 'Hood', 'Post_Time', 'Post_Title', 'URL']]\n",
    "\n",
    "apts_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send data to SlackBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from slackclient import SlackClient\n",
    "import pprint\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slack_data = apts_data.to_dict('records')\n",
    "str(slack_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the nicely formatted dictionary\n",
    "pprint.pprint(slack_data)\n",
    "\n",
    "# Sets 'pretty_dict_str' to \n",
    "pretty_dict_str = pprint.pformat(slack_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLACK_TOKEN = \"ENTER_SLACK_API\"\n",
    "SLACK_CHANNEL = \"ENTER_SLACK_CHANNEL\"\n",
    "\n",
    "sc = SlackClient(SLACK_TOKEN)\n",
    "\n",
    "sc.api_call(\n",
    "    \"chat.postMessage\", channel=SLACK_CHANNEL, text=pretty_dict_str,\n",
    "    username='pybot', icon_emoji=':robot_face:'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
