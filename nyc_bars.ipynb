{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'categories': [{'categories': {'id': 1, 'name': 'Delivery'}}, {'categories': {'id': 2, 'name': 'Dine-out'}}, {'categories': {'id': 3, 'name': 'Nightlife'}}, {'categories': {'id': 4, 'name': 'Catching-up'}}, {'categories': {'id': 5, 'name': 'Takeaway'}}, {'categories': {'id': 6, 'name': 'Cafes'}}, {'categories': {'id': 7, 'name': 'Daily Menus'}}, {'categories': {'id': 8, 'name': 'Breakfast'}}, {'categories': {'id': 9, 'name': 'Lunch'}}, {'categories': {'id': 10, 'name': 'Dinner'}}, {'categories': {'id': 11, 'name': 'Pubs & Bars'}}, {'categories': {'id': 13, 'name': 'Pocket Friendly Delivery'}}, {'categories': {'id': 14, 'name': 'Clubs & Lounges'}}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "Key = '06e95084cb5d3426c57b51987827eb7d'\n",
    "url = \"https://developers.zomato.com/api/v2.1/categories\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    r = requests.get(url, headers={'user-key': Key})\n",
    "    if r.ok:\n",
    "        data = r.json()\n",
    "        print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params= {\n",
    "    'user-key': Key,\n",
    "    \"category\": 3,\n",
    "    \"city\": 280,\n",
    "    \"entity_type\": \"city\",\n",
    "}\n",
    "\n",
    "url = \"https://developers.zomato.com/api/v2.1/categories\"\n",
    "\n",
    "headers= {\n",
    "    \"user-key\": \"06e95084cb5d3426c57b51987827eb7d\"\n",
    "}\n",
    "results = requests.get(url,headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 403, 'status': 'Forbidden', 'message': 'Invalid API Key'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to BeautifulSoup and define the parser as HTML\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all apts that fit the specified criteria and # of apts\n",
    "apts = soup.find_all('p', attrs={'class':'result-info'})\n",
    "print(len(apts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Parse through Craigslist results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results are returned as an iterable list\n",
    "results = soup.find_all('li', class_=\"result-row\")\n",
    "list_results = []\n",
    "\n",
    "\n",
    "# Loop through returned results\n",
    "for result in results:\n",
    "    # Error handling\n",
    "    try:\n",
    "        # Identify and return title of listing\n",
    "        title = result.find('a', class_=\"result-title\").text\n",
    "        # Identify and return price of listing\n",
    "        price = result.a.span.text.strip('$')\n",
    "        # Identify number of rooms\n",
    "        n_rooms = result.find('span', class_ = 'housing').text.split()\n",
    "        # Identify and return link to listing\n",
    "        link = result.a['href']\n",
    "        # Identify posting date\n",
    "        post_time = result.find('time')['datetime']\n",
    "        post_time = pd.to_datetime(post_time)\n",
    "        # Identify neighborhood\n",
    "        neighborhood = result.find('span', class_= 'result-hood').text\n",
    "        \n",
    "        list_results.append({'#bedrooms': n_rooms, '$price': price,\n",
    "                        'Post_Title': title, 'URL': link, 'Post_Time': post_time, 'Neighborhood': neighborhood})\n",
    "        \n",
    "        # Print results only if title, price, and link are available\n",
    "        if (title and price and link):\n",
    "            print('-------------')\n",
    "            print(title)\n",
    "            print(price)\n",
    "            print(n_rooms)\n",
    "            print(link)\n",
    "            print(post_time)\n",
    "            print(neighborhood)\n",
    "    except AttributeError as e:\n",
    "        print(e)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame from results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "apt_df = pd.DataFrame(list_results)\n",
    "\n",
    "# Clean data and remove text for room/ \n",
    "bedrooms = apt_df['#bedrooms']\n",
    "rooms = []\n",
    "\n",
    "for room in bedrooms:\n",
    "    rooms.append(room[0].strip('br'))\n",
    "\n",
    "apt_df['#rooms'] = rooms\n",
    "apt_df['Post_Time'] = apt_df['Post_Time'].dt.date\n",
    "\n",
    "apt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clean data and remove text from #bedrooms and create new column for sqft \n",
    "\n",
    "# Split before and after the dash & remove the 'ft2' text\n",
    "apt_df['#bedrooms'] = apt_df['#bedrooms'].astype(str)\n",
    "apt_df['#bedrooms'] = apt_df['#bedrooms'].str.split(',').str[2]\n",
    "apt_df['#bedrooms'].fillna(\"\", inplace=True)\n",
    "apt_df['#bedrooms'] = apt_df['#bedrooms'].str.split('ft2') \n",
    "\n",
    "###############################################################\n",
    "\n",
    "# Loop through the new bedroom values and remove remaining text that will prevent converting to int\n",
    "bedrooms = apt_df['#bedrooms']\n",
    "rooms = []\n",
    "\n",
    "for room in bedrooms:\n",
    "    rooms.append(room[0].strip(','))\n",
    "\n",
    "apt_df['sqft'] = rooms\n",
    "apt_df['sqft'] = apt_df['sqft'].str.replace(r\"'\", '')\n",
    "apt_df['sqft'] = apt_df['sqft'].astype(str)\n",
    "apt_df['sqft'] = apt_df['sqft'].str.strip()\n",
    "\n",
    "##############################################################\n",
    "\n",
    "# Convert values to int and if NAN make = 0\n",
    "sqfts = apt_df['sqft']\n",
    "number = []\n",
    "\n",
    "for sqft in sqfts:\n",
    "    number.append(sqft)\n",
    "\n",
    "newsqft = pd.to_numeric(number, errors='ignore')\n",
    "apt_df['sqft'] = newsqft\n",
    "apt_df['sqft'].fillna(\"0\", inplace=True)\n",
    "apt_df['sqft'] = apt_df['sqft'].astype(int)\n",
    "\n",
    "##############################################################\n",
    "\n",
    "# Convert price and # rooms to int in order to graph data\n",
    "apt_df['$price'] = apt_df['$price'].astype(int)\n",
    "apt_df['#rooms'] = apt_df['#rooms'].astype(int)\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "# Clean up the Neighborhood name\n",
    "apt_df['Hood'] = apt_df['Neighborhood'].str.extract(r\"\\((.*?)\\)\", expand=False)\n",
    "apt_df['Hood'] = apt_df['Hood'].astype(str)\n",
    "apt_df['Hood'] = apt_df['Hood'].str.strip()\n",
    "\n",
    "neighborhoods = apt_df[\"Hood\"].unique()\n",
    "new_hoods = ['North Beach', 'Lower Nob Hill', 'Nob Hill', 'Russian Hill', 'Lower Pac Hts', 'Pac Heights']\n",
    "my_dict = dict(zip(neighborhoods, new_hoods))\n",
    "\n",
    "apt_df['Hood'].replace(my_dict, inplace=True)\n",
    "\n",
    "\n",
    "apt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# New DataFrame to build graphs in\n",
    "apts_data = apt_df[['#rooms', 'sqft', '$price', 'Hood', 'Post_Time', 'Post_Title', 'URL']]\n",
    "\n",
    "apts_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send data to SlackBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from slackclient import SlackClient\n",
    "import pprint\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slack_data = apts_data.to_dict('records')\n",
    "str(slack_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the nicely formatted dictionary\n",
    "pprint.pprint(slack_data)\n",
    "\n",
    "# Sets 'pretty_dict_str' to \n",
    "pretty_dict_str = pprint.pformat(slack_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLACK_TOKEN = \"ENTER_SLACK_API\"\n",
    "SLACK_CHANNEL = \"ENTER_SLACK_CHANNEL\"\n",
    "\n",
    "sc = SlackClient(SLACK_TOKEN)\n",
    "\n",
    "sc.api_call(\n",
    "    \"chat.postMessage\", channel=SLACK_CHANNEL, text=pretty_dict_str,\n",
    "    username='pybot', icon_emoji=':robot_face:'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
